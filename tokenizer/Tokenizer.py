class Tokenizer:

    def encode(self, s):
        # s could be a batch of string, or string
        pass

    def decode(self, l):
        # l could be a batch of list of index, or a list of index 
        pass

    def bos_id(self):
        pass
    
    def eos_id(self):
        pass

    def unk_id(self):
        pass

    def pad_id(self):
        pass

    def vocab_size(self):
        pass

    def id2token(self, id):
        pass